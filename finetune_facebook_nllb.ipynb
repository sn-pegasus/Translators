{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b0g_wtOBSgHF",
        "outputId": "232b6c31-6f36-49dd-d825-2d0ad59719e8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Thu May  2 12:38:20 2024       \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 552.22                 Driver Version: 552.22         CUDA Version: 12.4     |\n",
            "|-----------------------------------------+------------------------+----------------------+\n",
            "| GPU  Name                     TCC/WDDM  | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                        |               MIG M. |\n",
            "|=========================================+========================+======================|\n",
            "|   0  NVIDIA GeForce RTX 3050 ...  WDDM  |   00000000:01:00.0  On |                  N/A |\n",
            "| N/A   64C    P0             13W /   80W |     769MiB /   4096MiB |      0%      Default |\n",
            "|                                         |                        |                  N/A |\n",
            "+-----------------------------------------+------------------------+----------------------+\n",
            "                                                                                         \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                              |\n",
            "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
            "|        ID   ID                                                               Usage      |\n",
            "|=========================================================================================|\n",
            "|    0   N/A  N/A      1064    C+G   ...nt.CBS_cw5n1h2txyewy\\SearchHost.exe      N/A      |\n",
            "|    0   N/A  N/A      4656    C+G   ...2txyewy\\StartMenuExperienceHost.exe      N/A      |\n",
            "|    0   N/A  N/A      5060    C+G   ...CBS_cw5n1h2txyewy\\TextInputHost.exe      N/A      |\n",
            "|    0   N/A  N/A      5972    C+G   ...0.0_x64__cv1g1gvanyjgm\\WhatsApp.exe      N/A      |\n",
            "|    0   N/A  N/A      6408    C+G   ...GeForce Experience\\NVIDIA Share.exe      N/A      |\n",
            "|    0   N/A  N/A     15752    C+G   ...\\AMD\\CNext\\CNext\\RadeonSoftware.exe      N/A      |\n",
            "|    0   N/A  N/A     17096    C+G   ...64__v826wp6bftszj\\TranslucentTB.exe      N/A      |\n",
            "|    0   N/A  N/A     18900    C+G   ...63.0_x64__zpdnekdrzrea0\\Spotify.exe      N/A      |\n",
            "|    0   N/A  N/A     22432    C+G   ...x86__97hta09mmv6hy\\Build\\Lively.exe      N/A      |\n",
            "|    0   N/A  N/A     24540    C+G   ...Programs\\Microsoft VS Code\\Code.exe      N/A      |\n",
            "|    0   N/A  N/A     26820    C+G   ...s\\System32\\ApplicationFrameHost.exe      N/A      |\n",
            "|    0   N/A  N/A     27088    C+G   ...lf\\0.248.120.19\\OverwolfBrowser.exe      N/A      |\n",
            "|    0   N/A  N/A     27872    C+G   C:\\Windows\\explorer.exe                     N/A      |\n",
            "|    0   N/A  N/A     30032    C+G   ...m Files (x86)\\Overwolf\\Overwolf.exe      N/A      |\n",
            "|    0   N/A  N/A     31404    C+G   ...US\\ArmouryDevice\\asus_framework.exe      N/A      |\n",
            "|    0   N/A  N/A     33076    C+G   C:\\Windows\\System32\\ShellHost.exe           N/A      |\n",
            "|    0   N/A  N/A     33612    C+G   ...siveControlPanel\\SystemSettings.exe      N/A      |\n",
            "|    0   N/A  N/A     35800    C+G   ...269_x64__8wekyb3d8bbwe\\ms-teams.exe      N/A      |\n",
            "|    0   N/A  N/A     36784    C+G   ...5n1h2txyewy\\ShellExperienceHost.exe      N/A      |\n",
            "|    0   N/A  N/A     38384    C+G   ...on\\124.0.2478.67\\msedgewebview2.exe      N/A      |\n",
            "|    0   N/A  N/A     38812    C+G   C:\\Program Files\\NordVPN\\NordVPN.exe        N/A      |\n",
            "|    0   N/A  N/A     39996    C+G   ...on\\124.0.2478.67\\msedgewebview2.exe      N/A      |\n",
            "|    0   N/A  N/A     40580    C+G   ...5911_x64__8wekyb3d8bbwe\\msteams.exe      N/A      |\n",
            "|    0   N/A  N/A     42748    C+G   ...les\\AMD\\CNext\\CNext\\AMDRSSrcExt.exe      N/A      |\n",
            "|    0   N/A  N/A     43608    C+G   ...Cloudflare WARP\\Cloudflare WARP.exe      N/A      |\n",
            "+-----------------------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "source": [
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zoJBTr01ZW6-",
        "outputId": "60d7be51-1911-4bf5-e841-a3fc545cf466"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        }
      ],
      "source": [
        "pip install datasets transformers[sentencepiece]  sacrebleu -q\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "FPdPJG-S3fqT",
        "outputId": "bf9739a2-3f3f-4bfc-e824-82fc420e3396"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>English</th>\n",
              "      <th>Sanskrit</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>Dhrtarastra said O Sanjaya ! What did my men a...</td>\n",
              "      <td>धृतराष्ट्र उवाच धर्मक्षेत्रे कुरुक्षेत्रे समवे...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>Sanjaya said Seeing the army of the sons of Pa...</td>\n",
              "      <td>सञ्जय उवाच दृष्ट्वा तु पाण्डवानीकं व्यूढं दुर्...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>O teacher ! Behold this mighty army of the son...</td>\n",
              "      <td>पश्यैतां पाण्डुपुत्राणामाचार्य महतीं चमूम्। व्...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>The heroes and mighty archers, comparable in w...</td>\n",
              "      <td>अत्र शूरा महेष्वासा भीमार्जुनसमा युधि। युयुधान...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>Dhrstaketu, Cekitana and the valourous king of...</td>\n",
              "      <td>धृष्टकेतुश्चेकितानः काशिराजश्च वीर्यवान्। पुरु...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26882</th>\n",
              "      <td>26882</td>\n",
              "      <td>and sought the somapourers home.</td>\n",
              "      <td>अगछःसोमिनो गर्हम|</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26883</th>\n",
              "      <td>26883</td>\n",
              "      <td>venya that mortal man hast thou for Āstrabudhn...</td>\n",
              "      <td>तवं तयमिन्द्र मर्त्यमास्त्रबुध्नाय वेन्यम|</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26884</th>\n",
              "      <td>26884</td>\n",
              "      <td>o indra many a time set free.</td>\n",
              "      <td>मुहुःश्रथ्ना मनस्यवे|</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26885</th>\n",
              "      <td>26885</td>\n",
              "      <td>bring indra to the east again that sun who now...</td>\n",
              "      <td>तवं तयमिन्द्र सूर्यं पश्चा सन्तं पुरस कर्धि|</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26886</th>\n",
              "      <td>26886</td>\n",
              "      <td>even against the will of gods.</td>\n",
              "      <td>देवानां चित तिरो वशम|</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>26887 rows × 3 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "       Unnamed: 0                                            English  \\\n",
              "0               0  Dhrtarastra said O Sanjaya ! What did my men a...   \n",
              "1               1  Sanjaya said Seeing the army of the sons of Pa...   \n",
              "2               2  O teacher ! Behold this mighty army of the son...   \n",
              "3               3  The heroes and mighty archers, comparable in w...   \n",
              "4               4  Dhrstaketu, Cekitana and the valourous king of...   \n",
              "...           ...                                                ...   \n",
              "26882       26882                   and sought the somapourers home.   \n",
              "26883       26883  venya that mortal man hast thou for Āstrabudhn...   \n",
              "26884       26884                      o indra many a time set free.   \n",
              "26885       26885  bring indra to the east again that sun who now...   \n",
              "26886       26886                     even against the will of gods.   \n",
              "\n",
              "                                                Sanskrit  \n",
              "0      धृतराष्ट्र उवाच धर्मक्षेत्रे कुरुक्षेत्रे समवे...  \n",
              "1      सञ्जय उवाच दृष्ट्वा तु पाण्डवानीकं व्यूढं दुर्...  \n",
              "2      पश्यैतां पाण्डुपुत्राणामाचार्य महतीं चमूम्। व्...  \n",
              "3      अत्र शूरा महेष्वासा भीमार्जुनसमा युधि। युयुधान...  \n",
              "4      धृष्टकेतुश्चेकितानः काशिराजश्च वीर्यवान्। पुरु...  \n",
              "...                                                  ...  \n",
              "26882                                  अगछःसोमिनो गर्हम|  \n",
              "26883         तवं तयमिन्द्र मर्त्यमास्त्रबुध्नाय वेन्यम|  \n",
              "26884                              मुहुःश्रथ्ना मनस्यवे|  \n",
              "26885       तवं तयमिन्द्र सूर्यं पश्चा सन्तं पुरस कर्धि|  \n",
              "26886                              देवानां चित तिरो वशम|  \n",
              "\n",
              "[26887 rows x 3 columns]"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load the dataset as a DataFrame\n",
        "data = pd.read_csv('C:\\\\Users\\\\sampa\\\\Downloads\\\\major\\\\san-eng.csv')\n",
        "data\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HCov--Qyd-FS",
        "outputId": "dac6dde8-a8ec-4508-f1e9-cef4e32948db"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[{'sn': 'धृतराष्ट्र उवाच धर्मक्षेत्रे कुरुक्षेत्रे समवेता युयुत्सवः। मामकाः पाण्डवाश्चैव किमकुर्वत सञ्जय।।',\n",
              "  'en': 'Dhrtarastra said O Sanjaya ! What did my men and the sons of Pandu do in the Kuruksetra, the field of righteousness, where the entire warring class has assembled ?orO Sanjaya ! What did the selfish intentions and the intentions born of wisdom do in the human body which is the field-of-duties, the repository of the senseorgans and in which all the murderous ones (passions and asceticism etc.) are confronting [each other].'},\n",
              " {'sn': 'सञ्जय उवाच दृष्ट्वा तु पाण्डवानीकं व्यूढं दुर्योधनस्तदा। आचार्यमुपसङ्गम्य राजा वचनमब्रवीत्।।',\n",
              "  'en': 'Sanjaya said Seeing the army of the sons of Pandu, marshalled in the military array, the prince Duryodhana approached the teacher (Drona) and spoke at that time, these words:'},\n",
              " {'sn': 'पश्यैतां पाण्डुपुत्राणामाचार्य महतीं चमूम्। व्यूढां द्रुपदपुत्रेण तव शिष्येण धीमता।।',\n",
              "  'en': \"O teacher ! Behold this mighty army of the sons of Pandu, marshalled in a military array by Drupada's son, your intelligent pupil.\"},\n",
              " {'sn': 'अत्र शूरा महेष्वासा भीमार्जुनसमा युधि। युयुधानो विराटश्च द्रुपदश्च महारथः।।',\n",
              "  'en': 'The heroes and mighty archers, comparable in war to Bhima and Arjuna, here are: Yuyudhana, the king of the Virata country, and Drupada, the mighty warrior;'},\n",
              " {'sn': 'धृष्टकेतुश्चेकितानः काशिराजश्च वीर्यवान्। पुरुजित्कुन्तिभोजश्च शैब्यश्च नरपुङ्गवः।।',\n",
              "  'en': 'Dhrstaketu, Cekitana and the valourous king of Kasi, and Kuntibhoja, the coneror of many,  and the Sibi king,  the best among men;'}]"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "data.rename(columns={data.columns[1]: \"en\", data.columns[2]: \"sn\"}, inplace=True)\n",
        "formatted_data = data[[\"sn\", \"en\"]].to_dict(orient='records')\n",
        "formatted_data[:5]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "km_DXGV6fB2O"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import sys\n",
        "import transformers\n",
        "import tensorflow as tf\n",
        "from datasets import load_dataset\n",
        "from transformers import AutoTokenizer\n",
        "from transformers import AutoModelForSeq2SeqLM,DataCollatorForSeq2Seq\n",
        "from transformers import AdamWeightDecay"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "umknjqwDfxTy"
      },
      "outputs": [],
      "source": [
        "model_checkpoint=\"facebook/nllb-200-distilled-600M\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        }
      ],
      "source": [
        "pip  install torch -q"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OycNvfgBf9A0",
        "outputId": "ceab2e5e-0a54-4923-b172-1a56adf6959d"
      },
      "outputs": [],
      "source": [
        "tokenizer=AutoTokenizer.from_pretrained(model_checkpoint)\n",
        "model = AutoModelForSeq2SeqLM.from_pretrained(\"facebook/nllb-200-distilled-600M\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vxpf4rdfgfN1",
        "outputId": "3fcb1517-1b9f-4356-cfa8-c68f29cea2ab"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'input_ids': [256047, 179085, 248372, 66580, 2734, 28770, 248281, 18887, 75829, 5229, 1248, 7598, 299, 7396, 2557, 248204, 965, 65799, 1645, 248225, 6893, 248442, 70803, 248204, 454, 48648, 91440, 197319, 124490, 80050, 24072, 248666, 5963, 248557, 58872, 44346, 248225, 248225, 2], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "tokenizer(\"पश्यैतां पाण्डुपुत्राणामाचार्य महतीं चमूम्। व्यूढां द्रुपदपुत्रेण तव शिष्येण धीमता।।\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "8cDQgqJFqHw-"
      },
      "outputs": [],
      "source": [
        "from torch.utils.data import Dataset, DataLoader\n",
        "import torch\n",
        "\n",
        "class TranslationDataset(Dataset):\n",
        "    def __init__(self, encodings):\n",
        "        self.encodings = encodings\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
        "        return item\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.encodings['input_ids'])\n",
        "def preprocess_data(data):\n",
        "    inputs = tokenizer([ex['sn'] for ex in data], max_length=128, truncation=True, padding='max_length', return_tensors=\"pt\")\n",
        "    targets = tokenizer([ex['en'] for ex in data], max_length=128, truncation=True, padding='max_length', return_tensors=\"pt\")\n",
        "    inputs['labels'] = targets['input_ids']\n",
        "    return inputs\n",
        "\n",
        "# Preprocess the entire dataset at once\n",
        "processed_data = preprocess_data(formatted_data)\n",
        "\n",
        "# Create a dataset from the processed data\n",
        "dataset = TranslationDataset(processed_data)\n",
        "\n",
        "# DataLoader for managing batches\n",
        "loader = DataLoader(dataset, batch_size=16, shuffle=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tIkP8kqZzCwi",
        "outputId": "c76018f1-db08-4784-a89d-c86863ea46ff"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\sampa\\AppData\\Local\\Temp\\ipykernel_29948\\3866316934.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "{'input_ids': tensor([256047,   3272,   8589, 190717,    692, 169905,  37087, 201392, 248139,\n",
              "         175805, 201392, 248139,   2382,   3479,    825,  11912,  12888, 101419,\n",
              "         120127, 248225,  31062, 154040,   2734,  28770,   1032,  16764,  56795,\n",
              "           1182, 248173,  15756,   5728, 248155, 128271,  87599, 248225, 248225,\n",
              "              2,      1,      1,      1,      1,      1,      1,      1,      1,\n",
              "              1,      1,      1,      1,      1,      1,      1,      1,      1,\n",
              "              1,      1,      1,      1,      1,      1,      1,      1,      1,\n",
              "              1,      1,      1,      1,      1,      1,      1,      1,      1,\n",
              "              1,      1,      1,      1,      1,      1,      1,      1,      1,\n",
              "              1,      1,      1,      1,      1,      1,      1,      1,      1,\n",
              "              1,      1,      1,      1,      1,      1,      1,      1,      1,\n",
              "              1,      1,      1,      1,      1,      1,      1,      1,      1,\n",
              "              1,      1,      1,      1,      1,      1,      1,      1,      1,\n",
              "              1,      1,      1,      1,      1,      1,      1,      1,      1,\n",
              "              1,      1]),\n",
              " 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0]),\n",
              " 'labels': tensor([256047,    122,   1853,   2786,  84594,  10833,    193,   6828,  43169,\n",
              "            835,   7644,   4077,   1537,    439,    540,    349,  59538,    452,\n",
              "            121,   3219,    359,    108,    349,   9317,   4775,  30750, 248079,\n",
              "            349,  60131,    452, 161352,  14710, 248079,  16346,    349,  92467,\n",
              "           2398,   8688,  54360,   3277, 102054,   2486,    385,     37, 248199,\n",
              "           6828,  43169,    835,   7644,   4077,    349,  27520,    680,  14721,\n",
              "           8856,    540,    349,  14721,   8856,  79519,    452, 200449,    359,\n",
              "            108,    349,  13585,  30602,   9089,    248,    349,  60131, 248105,\n",
              "           3533, 248105,    920,   5346, 248079,    349,    272,  93965,   6025,\n",
              "            452,    349,  26138,   9026,    621,    540,    108,   9089,   1910,\n",
              "            349,   5258, 248072,  92260,  55584,    104,   2121,  22840,    540,\n",
              "            388,  25484,    404,  10716,  32620,   5247,   2442,  95672,     87,\n",
              "            709, 248061,    795,  10603,   8479,      2,      1,      1,      1,\n",
              "              1,      1,      1,      1,      1,      1,      1,      1,      1,\n",
              "              1,      1])}"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "dataset[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        }
      ],
      "source": [
        "pip install accelerate -q"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "bu7Q34i-zygM",
        "outputId": "364d4ca0-01fd-4139-ef00-ee11335cb9dd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: transformers[torch] in c:\\users\\sampa\\anaconda3\\envs\\ml\\lib\\site-packages (4.40.1)\n",
            "Requirement already satisfied: filelock in c:\\users\\sampa\\anaconda3\\envs\\ml\\lib\\site-packages (from transformers[torch]) (3.14.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.19.3 in c:\\users\\sampa\\anaconda3\\envs\\ml\\lib\\site-packages (from transformers[torch]) (0.22.2)\n",
            "Requirement already satisfied: numpy>=1.17 in c:\\users\\sampa\\anaconda3\\envs\\ml\\lib\\site-packages (from transformers[torch]) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in c:\\users\\sampa\\anaconda3\\envs\\ml\\lib\\site-packages (from transformers[torch]) (24.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\sampa\\anaconda3\\envs\\ml\\lib\\site-packages (from transformers[torch]) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\sampa\\anaconda3\\envs\\ml\\lib\\site-packages (from transformers[torch]) (2023.12.25)\n",
            "Requirement already satisfied: requests in c:\\users\\sampa\\anaconda3\\envs\\ml\\lib\\site-packages (from transformers[torch]) (2.31.0)\n",
            "Requirement already satisfied: tokenizers<0.20,>=0.19 in c:\\users\\sampa\\anaconda3\\envs\\ml\\lib\\site-packages (from transformers[torch]) (0.19.1)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in c:\\users\\sampa\\anaconda3\\envs\\ml\\lib\\site-packages (from transformers[torch]) (0.4.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in c:\\users\\sampa\\anaconda3\\envs\\ml\\lib\\site-packages (from transformers[torch]) (4.66.2)\n",
            "Requirement already satisfied: torch in c:\\users\\sampa\\anaconda3\\envs\\ml\\lib\\site-packages (from transformers[torch]) (2.3.0)\n",
            "Requirement already satisfied: accelerate>=0.21.0 in c:\\users\\sampa\\anaconda3\\envs\\ml\\lib\\site-packages (from transformers[torch]) (0.29.3)\n",
            "Requirement already satisfied: psutil in c:\\users\\sampa\\anaconda3\\envs\\ml\\lib\\site-packages (from accelerate>=0.21.0->transformers[torch]) (5.9.8)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\sampa\\anaconda3\\envs\\ml\\lib\\site-packages (from huggingface-hub<1.0,>=0.19.3->transformers[torch]) (2024.3.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\sampa\\anaconda3\\envs\\ml\\lib\\site-packages (from huggingface-hub<1.0,>=0.19.3->transformers[torch]) (4.10.0)\n",
            "Requirement already satisfied: sympy in c:\\users\\sampa\\anaconda3\\envs\\ml\\lib\\site-packages (from torch->transformers[torch]) (1.12)\n",
            "Requirement already satisfied: networkx in c:\\users\\sampa\\anaconda3\\envs\\ml\\lib\\site-packages (from torch->transformers[torch]) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in c:\\users\\sampa\\anaconda3\\envs\\ml\\lib\\site-packages (from torch->transformers[torch]) (3.1.3)\n",
            "Requirement already satisfied: mkl<=2021.4.0,>=2021.1.1 in c:\\users\\sampa\\anaconda3\\envs\\ml\\lib\\site-packages (from torch->transformers[torch]) (2021.4.0)\n",
            "Requirement already satisfied: colorama in c:\\users\\sampa\\anaconda3\\envs\\ml\\lib\\site-packages (from tqdm>=4.27->transformers[torch]) (0.4.6)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\sampa\\anaconda3\\envs\\ml\\lib\\site-packages (from requests->transformers[torch]) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\sampa\\anaconda3\\envs\\ml\\lib\\site-packages (from requests->transformers[torch]) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\sampa\\anaconda3\\envs\\ml\\lib\\site-packages (from requests->transformers[torch]) (2.2.1)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\sampa\\anaconda3\\envs\\ml\\lib\\site-packages (from requests->transformers[torch]) (2024.2.2)\n",
            "Requirement already satisfied: intel-openmp==2021.* in c:\\users\\sampa\\anaconda3\\envs\\ml\\lib\\site-packages (from mkl<=2021.4.0,>=2021.1.1->torch->transformers[torch]) (2021.4.0)\n",
            "Requirement already satisfied: tbb==2021.* in c:\\users\\sampa\\anaconda3\\envs\\ml\\lib\\site-packages (from mkl<=2021.4.0,>=2021.1.1->torch->transformers[torch]) (2021.12.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\sampa\\anaconda3\\envs\\ml\\lib\\site-packages (from jinja2->torch->transformers[torch]) (2.1.5)\n",
            "Requirement already satisfied: mpmath>=0.19 in c:\\users\\sampa\\anaconda3\\envs\\ml\\lib\\site-packages (from sympy->torch->transformers[torch]) (1.3.0)\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        }
      ],
      "source": [
        "pip install transformers[torch] --upgrade\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xucs9YaKz6iy",
        "outputId": "f7eef2aa-3ef3-45b4-82bf-4fa18b4db57f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accelerate version: 0.29.3\n"
          ]
        }
      ],
      "source": [
        "import accelerate\n",
        "print(\"Accelerate version:\", accelerate.__version__)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 486
        },
        "id": "ybCv3sloqRN5",
        "outputId": "926e2378-d2bd-4c64-be74-967eb8759cc5"
      },
      "outputs": [
        {
          "ename": "ValueError",
          "evalue": "FP16 Mixed precision training with AMP or APEX (`--fp16`) and FP16 half precision evaluation (`--fp16_full_eval`) can only be used on CUDA or MLU devices or NPU devices or certain XPU devices (with IPEX).",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[18], line 4\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtransformers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Trainer, TrainingArguments\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcuda\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mamp\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m autocast\n\u001b[1;32m----> 4\u001b[0m training_args \u001b[38;5;241m=\u001b[39m \u001b[43mTrainingArguments\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m      5\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m./results\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m      6\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnum_train_epochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m      7\u001b[0m \u001b[43m    \u001b[49m\u001b[43mper_device_train_batch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m16\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m      8\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfp16\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Enable mixed precision\u001b[39;49;00m\n\u001b[0;32m      9\u001b[0m \u001b[43m    \u001b[49m\u001b[43mwarmup_steps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m500\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     10\u001b[0m \u001b[43m    \u001b[49m\u001b[43mweight_decay\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.01\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     11\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlogging_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m./logs\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     12\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlearning_rate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m5e-5\u001b[39;49m\n\u001b[0;32m     13\u001b[0m \u001b[43m)\u001b[49m\n\u001b[0;32m     15\u001b[0m trainer \u001b[38;5;241m=\u001b[39m Trainer(\n\u001b[0;32m     16\u001b[0m     model\u001b[38;5;241m=\u001b[39mmodel,\n\u001b[0;32m     17\u001b[0m     args\u001b[38;5;241m=\u001b[39mtraining_args,\n\u001b[0;32m     18\u001b[0m     train_dataset\u001b[38;5;241m=\u001b[39mdataset,\n\u001b[0;32m     19\u001b[0m     tokenizer\u001b[38;5;241m=\u001b[39mtokenizer\n\u001b[0;32m     20\u001b[0m )\n\u001b[0;32m     22\u001b[0m trainer\u001b[38;5;241m.\u001b[39mtrain()\n",
            "File \u001b[1;32m<string>:125\u001b[0m, in \u001b[0;36m__init__\u001b[1;34m(self, output_dir, overwrite_output_dir, do_train, do_eval, do_predict, evaluation_strategy, prediction_loss_only, per_device_train_batch_size, per_device_eval_batch_size, per_gpu_train_batch_size, per_gpu_eval_batch_size, gradient_accumulation_steps, eval_accumulation_steps, eval_delay, learning_rate, weight_decay, adam_beta1, adam_beta2, adam_epsilon, max_grad_norm, num_train_epochs, max_steps, lr_scheduler_type, lr_scheduler_kwargs, warmup_ratio, warmup_steps, log_level, log_level_replica, log_on_each_node, logging_dir, logging_strategy, logging_first_step, logging_steps, logging_nan_inf_filter, save_strategy, save_steps, save_total_limit, save_safetensors, save_on_each_node, save_only_model, no_cuda, use_cpu, use_mps_device, seed, data_seed, jit_mode_eval, use_ipex, bf16, fp16, fp16_opt_level, half_precision_backend, bf16_full_eval, fp16_full_eval, tf32, local_rank, ddp_backend, tpu_num_cores, tpu_metrics_debug, debug, dataloader_drop_last, eval_steps, dataloader_num_workers, dataloader_prefetch_factor, past_index, run_name, disable_tqdm, remove_unused_columns, label_names, load_best_model_at_end, metric_for_best_model, greater_is_better, ignore_data_skip, fsdp, fsdp_min_num_params, fsdp_config, fsdp_transformer_layer_cls_to_wrap, accelerator_config, deepspeed, label_smoothing_factor, optim, optim_args, adafactor, group_by_length, length_column_name, report_to, ddp_find_unused_parameters, ddp_bucket_cap_mb, ddp_broadcast_buffers, dataloader_pin_memory, dataloader_persistent_workers, skip_memory_metrics, use_legacy_prediction_loop, push_to_hub, resume_from_checkpoint, hub_model_id, hub_strategy, hub_token, hub_private_repo, hub_always_push, gradient_checkpointing, gradient_checkpointing_kwargs, include_inputs_for_metrics, eval_do_concat_batches, fp16_backend, push_to_hub_model_id, push_to_hub_organization, push_to_hub_token, mp_parameters, auto_find_batch_size, full_determinism, torchdynamo, ray_scope, ddp_timeout, torch_compile, torch_compile_backend, torch_compile_mode, dispatch_batches, split_batches, include_tokens_per_second, include_num_input_tokens_seen, neftune_noise_alpha, optim_target_modules)\u001b[0m\n",
            "File \u001b[1;32mc:\\Users\\sampa\\anaconda3\\envs\\ml\\lib\\site-packages\\transformers\\training_args.py:1612\u001b[0m, in \u001b[0;36mTrainingArguments.__post_init__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1600\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m--optim adamw_torch_fused with --fp16 requires PyTorch>2.0\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m   1602\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[0;32m   1603\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mframework \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpt\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1604\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m is_torch_available()\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1610\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfp16 \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfp16_full_eval)\n\u001b[0;32m   1611\u001b[0m ):\n\u001b[1;32m-> 1612\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   1613\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFP16 Mixed precision training with AMP or APEX (`--fp16`) and FP16 half precision evaluation\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1614\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m (`--fp16_full_eval`) can only be used on CUDA or MLU devices or NPU devices or certain XPU devices (with IPEX).\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1615\u001b[0m     )\n\u001b[0;32m   1617\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[0;32m   1618\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mframework \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpt\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1619\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m is_torch_available()\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1627\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbf16 \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbf16_full_eval)\n\u001b[0;32m   1628\u001b[0m ):\n\u001b[0;32m   1629\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   1630\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBF16 Mixed precision training with AMP (`--bf16`) and BF16 half precision evaluation\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1631\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m (`--bf16_full_eval`) can only be used on CUDA, XPU (with IPEX), NPU, MLU or CPU/TPU/NeuronCore devices.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1632\u001b[0m     )\n",
            "\u001b[1;31mValueError\u001b[0m: FP16 Mixed precision training with AMP or APEX (`--fp16`) and FP16 half precision evaluation (`--fp16_full_eval`) can only be used on CUDA or MLU devices or NPU devices or certain XPU devices (with IPEX)."
          ]
        }
      ],
      "source": [
        "from transformers import Trainer, TrainingArguments\n",
        "from torch.cuda.amp import autocast\n",
        "\n",
        "training_args = TrainingArguments(\n",
        "    output_dir='./results',\n",
        "    num_train_epochs=3,\n",
        "    per_device_train_batch_size=16,\n",
        "    fp16=True,  # Enable mixed precision\n",
        "    warmup_steps=500,\n",
        "    weight_decay=0.01,\n",
        "    logging_dir='./logs',\n",
        "    learning_rate=5e-5\n",
        ")\n",
        "\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=dataset,\n",
        "    tokenizer=tokenizer\n",
        ")\n",
        "\n",
        "trainer.train()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.19"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
