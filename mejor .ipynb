{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "Xv2eecqOwpVO"
      },
      "outputs": [],
      "source": [
        "import pathlib\n",
        "import random\n",
        "import string\n",
        "import re\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.layers import TextVectorization\n",
        "from tensorflow.keras.layers import Bidirectional,GRU,LSTM,Embedding\n",
        "from tensorflow.keras.layers import Dense,MultiHeadAttention,LayerNormalization,Embedding,Dropout,Layer\n",
        "from tensorflow.keras import Sequential,Input\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint\n",
        "import os \n",
        "from nltk.translate.bleu_score import sentence_bleu"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wTWHbBltoVk2",
        "outputId": "1e957671-227f-41a2-b648-76211d6ebafa"
      },
      "outputs": [],
      "source": [
        "    # %cd C:/Users/Lenovo/Desktop/CODING/major_project/parallel-corpus/sanskrit-english\n",
        "    # %ls"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Number of sentence pairs created: 34374\n"
          ]
        }
      ],
      "source": [
        "file_directory = r'C://Users//sampa//Downloads/sanskrit-english-20240406T035746Z-001/sanskrit-english'\n",
        "\n",
        "import os\n",
        "\n",
        "# Function to read lines from a file and remove newline characters\n",
        "def read_lines(file_path):\n",
        "    with open(file_path, 'r', encoding='utf-8') as f:\n",
        "        return [line.strip() for line in f.readlines()]\n",
        "\n",
        "# Paths to English and Sanskrit files\n",
        "english_files = [\n",
        "    file_directory  +'//bhagvadgita_english.txt',\n",
        "    file_directory  +'//bible_english.txt',\n",
        "    file_directory  +'//manu_english.txt',\n",
        "    file_directory  +'//ramayan_english.txt',\n",
        "    file_directory  +'//rigveda_english.txt'\n",
        "]\n",
        "\n",
        "sanskrit_files = [\n",
        "    file_directory  +'//bhagvadgita_sanskrit.txt',\n",
        "    file_directory  +'//bible_sanskrit.txt',\n",
        "    file_directory  +'//manu_sanskrit.txt',\n",
        "    file_directory  + '//ramayan_sanskrit.txt',\n",
        "    file_directory  +'//rigveda_sanskrit.txt'\n",
        "]\n",
        "\n",
        "# Read English and Sanskrit lines from respective files\n",
        "eng_lines = []\n",
        "sanskrit_lines = []\n",
        "\n",
        "for eng_file, sanskrit_file in zip(english_files, sanskrit_files):\n",
        "    eng_lines.extend(read_lines(os.path.join(file_directory, eng_file)))\n",
        "    sanskrit_lines.extend(read_lines(os.path.join(file_directory, sanskrit_file)))\n",
        "\n",
        "# Create pairs of English and Sanskrit sentences\n",
        "sentence_pairs = []\n",
        "\n",
        "for eng_sentence, sanskrit_sentence in zip(eng_lines, sanskrit_lines):\n",
        "    sentence_pairs.append((eng_sentence, '[start] ' + sanskrit_sentence + ' [end]'))\n",
        "\n",
        "print(\"Number of sentence pairs created:\", len(sentence_pairs))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Rbcc-na52dlN",
        "outputId": "64f23f3c-f3ac-4000-9839-00188eb235a6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "('lightly with piercing ends as \\x92twere two ranks of heroes ranged for fight.', '[start] नेमधितान पौंस्या वर्थेव विष्टान्ता| [end]')\n"
          ]
        }
      ],
      "source": [
        "import random\n",
        "print(random.choice(sentence_pairs))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TOMK1qsp3djy",
        "outputId": "8c3e3f5f-1155-4f37-db09-9c60c594e75e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                                             English  \\\n",
            "0  Dhrtarastra said O Sanjaya ! What did my men a...   \n",
            "1  Sanjaya said Seeing the army of the sons of Pa...   \n",
            "2  O teacher ! Behold this mighty army of the son...   \n",
            "3  The heroes and mighty archers, comparable in w...   \n",
            "4  Dhrstaketu, Cekitana and the valourous king of...   \n",
            "\n",
            "                                            Sanskrit  \n",
            "0  [start] धृतराष्ट्र उवाच धर्मक्षेत्रे कुरुक्षेत...  \n",
            "1  [start] सञ्जय उवाच दृष्ट्वा तु पाण्डवानीकं व्य...  \n",
            "2  [start] पश्यैतां पाण्डुपुत्राणामाचार्य महतीं च...  \n",
            "3  [start] अत्र शूरा महेष्वासा भीमार्जुनसमा युधि।...  \n",
            "4  [start] धृष्टकेतुश्चेकितानः काशिराजश्च वीर्यवा...  \n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Assuming 'sentence_pairs' contains pairs of English and Sanskrit sentences\n",
        "# Split the pairs into two lists: one for English and one for Sanskrit\n",
        "english_sentences = [pair[0] for pair in sentence_pairs]\n",
        "sanskrit_sentences = [pair[1] for pair in sentence_pairs]\n",
        "\n",
        "# Create a DataFrame with these lists\n",
        "df = pd.DataFrame({\n",
        "    'English': english_sentences,\n",
        "    'Sanskrit': sanskrit_sentences\n",
        "})\n",
        "# Remove '[start]' and '[end]' tokens from the 'Sanskrit' column\n",
        "df['Sanskrit'] = df['Sanskrit'].str.replace('\\[start\\] ', '')  # Remove '[start]' and the following space\n",
        "df['Sanskrit'] = df['Sanskrit'].str.replace(' \\[end\\]', '')  # Remove '[end]' and the preceding space\n",
        "\n",
        "# Display the first few rows of the DataFrame to verify the changes\n",
        "print(df.head())\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "ocXUKTGnZVTp",
        "outputId": "c99af9d9-246f-46a4-ba6e-194d86955e3a"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>English</th>\n",
              "      <th>Sanskrit</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Dhrtarastra said O Sanjaya ! What did my men a...</td>\n",
              "      <td>[start] धृतराष्ट्र उवाच धर्मक्षेत्रे कुरुक्षेत...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Sanjaya said Seeing the army of the sons of Pa...</td>\n",
              "      <td>[start] सञ्जय उवाच दृष्ट्वा तु पाण्डवानीकं व्य...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>O teacher ! Behold this mighty army of the son...</td>\n",
              "      <td>[start] पश्यैतां पाण्डुपुत्राणामाचार्य महतीं च...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>The heroes and mighty archers, comparable in w...</td>\n",
              "      <td>[start] अत्र शूरा महेष्वासा भीमार्जुनसमा युधि।...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Dhrstaketu, Cekitana and the valourous king of...</td>\n",
              "      <td>[start] धृष्टकेतुश्चेकितानः काशिराजश्च वीर्यवा...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>34369</th>\n",
              "      <td>and sought the somapourers home.</td>\n",
              "      <td>[start] अगछःसोमिनो गर्हम| [end]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>34370</th>\n",
              "      <td>venya that mortal man hast thou for Āstrabudhn...</td>\n",
              "      <td>[start] तवं तयमिन्द्र मर्त्यमास्त्रबुध्नाय वेन...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>34371</th>\n",
              "      <td>o indra many a time set free.</td>\n",
              "      <td>[start] मुहुःश्रथ्ना मनस्यवे| [end]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>34372</th>\n",
              "      <td>bring indra to the east again that sun who now...</td>\n",
              "      <td>[start] तवं तयमिन्द्र सूर्यं पश्चा सन्तं पुरस ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>34373</th>\n",
              "      <td>even against the will of gods.</td>\n",
              "      <td>[start] देवानां चित तिरो वशम| [end]</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>34374 rows × 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                 English  \\\n",
              "0      Dhrtarastra said O Sanjaya ! What did my men a...   \n",
              "1      Sanjaya said Seeing the army of the sons of Pa...   \n",
              "2      O teacher ! Behold this mighty army of the son...   \n",
              "3      The heroes and mighty archers, comparable in w...   \n",
              "4      Dhrstaketu, Cekitana and the valourous king of...   \n",
              "...                                                  ...   \n",
              "34369                   and sought the somapourers home.   \n",
              "34370  venya that mortal man hast thou for Āstrabudhn...   \n",
              "34371                      o indra many a time set free.   \n",
              "34372  bring indra to the east again that sun who now...   \n",
              "34373                     even against the will of gods.   \n",
              "\n",
              "                                                Sanskrit  \n",
              "0      [start] धृतराष्ट्र उवाच धर्मक्षेत्रे कुरुक्षेत...  \n",
              "1      [start] सञ्जय उवाच दृष्ट्वा तु पाण्डवानीकं व्य...  \n",
              "2      [start] पश्यैतां पाण्डुपुत्राणामाचार्य महतीं च...  \n",
              "3      [start] अत्र शूरा महेष्वासा भीमार्जुनसमा युधि।...  \n",
              "4      [start] धृष्टकेतुश्चेकितानः काशिराजश्च वीर्यवा...  \n",
              "...                                                  ...  \n",
              "34369                    [start] अगछःसोमिनो गर्हम| [end]  \n",
              "34370  [start] तवं तयमिन्द्र मर्त्यमास्त्रबुध्नाय वेन...  \n",
              "34371                [start] मुहुःश्रथ्ना मनस्यवे| [end]  \n",
              "34372  [start] तवं तयमिन्द्र सूर्यं पश्चा सन्तं पुरस ...  \n",
              "34373                [start] देवानां चित तिरो वशम| [end]  \n",
              "\n",
              "[34374 rows x 2 columns]"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "BkVDRbmHZVrr"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "# Tokenize Sanskrit sentences\n",
        "sanskrit_tokenizer = Tokenizer(char_level=False)\n",
        "sanskrit_tokenizer.fit_on_texts(df['Sanskrit'])\n",
        "sanskrit_sequences = sanskrit_tokenizer.texts_to_sequences(df['Sanskrit'])\n",
        "\n",
        "# Tokenize English sentences\n",
        "english_tokenizer = Tokenizer(char_level=False, filters='')\n",
        "english_tokenizer.fit_on_texts(df['English'])\n",
        "english_sequences = english_tokenizer.texts_to_sequences(df['English'])\n",
        "\n",
        "# Vocabulary sizes\n",
        "sanskrit_vocab_size = len(sanskrit_tokenizer.word_index) + 1\n",
        "english_vocab_size = len(english_tokenizer.word_index) + 1\n",
        "\n",
        "# Padding sequences\n",
        "sanskrit_padded = pad_sequences(sanskrit_sequences, padding='post')\n",
        "english_padded = pad_sequences(english_sequences, padding='post')\n",
        "\n",
        "# Decoder Input Data\n",
        "decoder_input_data = english_padded[:, :-1]\n",
        "\n",
        "# Decoder Target Data\n",
        "decoder_target_data = np.zeros_like(decoder_input_data)\n",
        "decoder_target_data[:, :-1] = decoder_input_data[:, 1:]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "def one_hot_encode(sequences, num_classes, dtype=np.float32):\n",
        "    # ... (rest of the function)\n",
        "    one_hot_output = np.zeros((len(sequences), max(len(sequence) for sequence in sequences), num_classes), dtype=dtype)\n",
        "    # ... (rest of the function)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "5312OSl8b43-"
      },
      "outputs": [
        {
          "ename": "MemoryError",
          "evalue": "Unable to allocate 1.24 TiB for an array with shape (34374, 226, 43947) and data type float32",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[9], line 16\u001b[0m\n\u001b[0;32m     14\u001b[0m     one_hot_output \u001b[38;5;241m=\u001b[39m csr_matrix((data, (rows, cols)), shape\u001b[38;5;241m=\u001b[39m(\u001b[38;5;28mlen\u001b[39m(sequences), max_sequence_length, num_classes), dtype\u001b[38;5;241m=\u001b[39mdtype)\n\u001b[0;32m     15\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m one_hot_output\n\u001b[1;32m---> 16\u001b[0m decoder_target_one_hot \u001b[38;5;241m=\u001b[39m \u001b[43mone_hot_encode\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdecoder_target_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43menglish_vocab_size\u001b[49m\u001b[43m)\u001b[49m\n",
            "Cell \u001b[1;32mIn[8], line 5\u001b[0m, in \u001b[0;36mone_hot_encode\u001b[1;34m(sequences, num_classes, dtype)\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mone_hot_encode\u001b[39m(sequences, num_classes, dtype\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39mfloat32):\n\u001b[0;32m      4\u001b[0m     \u001b[38;5;66;03m# ... (rest of the function)\u001b[39;00m\n\u001b[1;32m----> 5\u001b[0m     one_hot_output \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mzeros\u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43msequences\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mmax\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43msequence\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43msequence\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43msequences\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_classes\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[1;31mMemoryError\u001b[0m: Unable to allocate 1.24 TiB for an array with shape (34374, 226, 43947) and data type float32"
          ]
        }
      ],
      "source": [
        "def one_hot_encode_sparse(sequences, num_classes, dtype=np.float32):\n",
        "    rows = []\n",
        "    cols = []\n",
        "    data = []\n",
        "    max_sequence_length = max(len(sequence) for sequence in sequences)\n",
        "    \n",
        "    for i, sequence in enumerate(sequences):\n",
        "        for t, word_index in enumerate(sequence):\n",
        "            if word_index > 0:  # Skip 0 padding\n",
        "                rows.append(i)\n",
        "                cols.append(t)\n",
        "                data.append(1.0)\n",
        "    \n",
        "    one_hot_output = csr_matrix((data, (rows, cols)), shape=(len(sequences), max_sequence_length, num_classes), dtype=dtype)\n",
        "    return one_hot_output\n",
        "decoder_target_one_hot = one_hot_encode(decoder_target_data, english_vocab_size)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a873cKWhcCBp"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.layers import Input, LSTM, Dense, Embedding\n",
        "from tensorflow.keras.models import Model\n",
        "\n",
        "latent_dim = 256  # Dimensionality of the encoding space\n",
        "\n",
        "# Encoder\n",
        "encoder_inputs = Input(shape=(None,))\n",
        "encoder_embedding = Embedding(input_dim=sanskrit_vocab_size, output_dim=latent_dim)\n",
        "encoder_lstm = LSTM(latent_dim, return_state=True)\n",
        "encoder_outputs, state_h, state_c = encoder_lstm(encoder_embedding(encoder_inputs))\n",
        "encoder_states = [state_h, state_c]\n",
        "\n",
        "# Decoder\n",
        "decoder_inputs = Input(shape=(None,))\n",
        "decoder_embedding = Embedding(input_dim=english_vocab_size, output_dim=latent_dim)\n",
        "decoder_lstm = LSTM(latent_dim, return_sequences=True, return_state=True)\n",
        "decoder_outputs, _, _ = decoder_lstm(decoder_embedding(decoder_inputs), initial_state=encoder_states)\n",
        "decoder_dense = Dense(english_vocab_size, activation='softmax')\n",
        "decoder_outputs = decoder_dense(decoder_outputs)\n",
        "\n",
        "# Define the model\n",
        "model = Model([encoder_inputs, decoder_inputs], decoder_outputs)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jqi-Kg8ZcEJz",
        "outputId": "ed3973db-ecda-456c-c1de-d2fe2982ac69"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_1 (InputLayer)           [(None, None)]       0           []                               \n",
            "                                                                                                  \n",
            " input_2 (InputLayer)           [(None, None)]       0           []                               \n",
            "                                                                                                  \n",
            " embedding (Embedding)          (None, None, 256)    32082432    ['input_1[0][0]']                \n",
            "                                                                                                  \n",
            " embedding_1 (Embedding)        (None, None, 256)    11250432    ['input_2[0][0]']                \n",
            "                                                                                                  \n",
            " lstm (LSTM)                    [(None, 256),        525312      ['embedding[0][0]']              \n",
            "                                 (None, 256),                                                     \n",
            "                                 (None, 256)]                                                     \n",
            "                                                                                                  \n",
            " lstm_1 (LSTM)                  [(None, None, 256),  525312      ['embedding_1[0][0]',            \n",
            "                                 (None, 256),                     'lstm[0][1]',                   \n",
            "                                 (None, 256)]                     'lstm[0][2]']                   \n",
            "                                                                                                  \n",
            " dense (Dense)                  (None, None, 43947)  11294379    ['lstm_1[0][0]']                 \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 55,677,867\n",
            "Trainable params: 55,677,867\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ar_kznKdcF1m"
      },
      "outputs": [],
      "source": [
        "model.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['accuracy'])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D_O5-icBpujz",
        "outputId": "5f5afbf7-7274-40cd-e356-a8550d30ff63"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n"
          ]
        },
        {
          "ename": "ResourceExhaustedError",
          "evalue": "Graph execution error:\n\nDetected at node 'model/dense/Tensordot/MatMul' defined at (most recent call last):\n    File \"c:\\Users\\sampa\\anaconda3\\envs\\ml\\lib\\runpy.py\", line 197, in _run_module_as_main\n      return _run_code(code, main_globals, None,\n    File \"c:\\Users\\sampa\\anaconda3\\envs\\ml\\lib\\runpy.py\", line 87, in _run_code\n      exec(code, run_globals)\n    File \"c:\\Users\\sampa\\anaconda3\\envs\\ml\\lib\\site-packages\\ipykernel_launcher.py\", line 18, in <module>\n      app.launch_new_instance()\n    File \"c:\\Users\\sampa\\anaconda3\\envs\\ml\\lib\\site-packages\\traitlets\\config\\application.py\", line 1075, in launch_instance\n      app.start()\n    File \"c:\\Users\\sampa\\anaconda3\\envs\\ml\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 739, in start\n      self.io_loop.start()\n    File \"c:\\Users\\sampa\\anaconda3\\envs\\ml\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 205, in start\n      self.asyncio_loop.run_forever()\n    File \"c:\\Users\\sampa\\anaconda3\\envs\\ml\\lib\\asyncio\\base_events.py\", line 601, in run_forever\n      self._run_once()\n    File \"c:\\Users\\sampa\\anaconda3\\envs\\ml\\lib\\asyncio\\base_events.py\", line 1905, in _run_once\n      handle._run()\n    File \"c:\\Users\\sampa\\anaconda3\\envs\\ml\\lib\\asyncio\\events.py\", line 80, in _run\n      self._context.run(self._callback, *self._args)\n    File \"c:\\Users\\sampa\\anaconda3\\envs\\ml\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 545, in dispatch_queue\n      await self.process_one()\n    File \"c:\\Users\\sampa\\anaconda3\\envs\\ml\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 534, in process_one\n      await dispatch(*args)\n    File \"c:\\Users\\sampa\\anaconda3\\envs\\ml\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 437, in dispatch_shell\n      await result\n    File \"c:\\Users\\sampa\\anaconda3\\envs\\ml\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 359, in execute_request\n      await super().execute_request(stream, ident, parent)\n    File \"c:\\Users\\sampa\\anaconda3\\envs\\ml\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 778, in execute_request\n      reply_content = await reply_content\n    File \"c:\\Users\\sampa\\anaconda3\\envs\\ml\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 446, in do_execute\n      res = shell.run_cell(\n    File \"c:\\Users\\sampa\\anaconda3\\envs\\ml\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 549, in run_cell\n      return super().run_cell(*args, **kwargs)\n    File \"c:\\Users\\sampa\\anaconda3\\envs\\ml\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3048, in run_cell\n      result = self._run_cell(\n    File \"c:\\Users\\sampa\\anaconda3\\envs\\ml\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3103, in _run_cell\n      result = runner(coro)\n    File \"c:\\Users\\sampa\\anaconda3\\envs\\ml\\lib\\site-packages\\IPython\\core\\async_helpers.py\", line 129, in _pseudo_sync_runner\n      coro.send(None)\n    File \"c:\\Users\\sampa\\anaconda3\\envs\\ml\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3308, in run_cell_async\n      has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n    File \"c:\\Users\\sampa\\anaconda3\\envs\\ml\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3490, in run_ast_nodes\n      if await self.run_code(code, result, async_=asy):\n    File \"c:\\Users\\sampa\\anaconda3\\envs\\ml\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3550, in run_code\n      exec(code_obj, self.user_global_ns, self.user_ns)\n    File \"C:\\Users\\sampa\\AppData\\Local\\Temp\\ipykernel_24880\\1564568496.py\", line 7, in <module>\n      model.fit([sanskrit_padded, decoder_input_data], decoder_target_data,\n    File \"c:\\Users\\sampa\\anaconda3\\envs\\ml\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"c:\\Users\\sampa\\anaconda3\\envs\\ml\\lib\\site-packages\\keras\\engine\\training.py\", line 1564, in fit\n      tmp_logs = self.train_function(iterator)\n    File \"c:\\Users\\sampa\\anaconda3\\envs\\ml\\lib\\site-packages\\keras\\engine\\training.py\", line 1160, in train_function\n      return step_function(self, iterator)\n    File \"c:\\Users\\sampa\\anaconda3\\envs\\ml\\lib\\site-packages\\keras\\engine\\training.py\", line 1146, in step_function\n      outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"c:\\Users\\sampa\\anaconda3\\envs\\ml\\lib\\site-packages\\keras\\engine\\training.py\", line 1135, in run_step\n      outputs = model.train_step(data)\n    File \"c:\\Users\\sampa\\anaconda3\\envs\\ml\\lib\\site-packages\\keras\\engine\\training.py\", line 993, in train_step\n      y_pred = self(x, training=True)\n    File \"c:\\Users\\sampa\\anaconda3\\envs\\ml\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"c:\\Users\\sampa\\anaconda3\\envs\\ml\\lib\\site-packages\\keras\\engine\\training.py\", line 557, in __call__\n      return super().__call__(*args, **kwargs)\n    File \"c:\\Users\\sampa\\anaconda3\\envs\\ml\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"c:\\Users\\sampa\\anaconda3\\envs\\ml\\lib\\site-packages\\keras\\engine\\base_layer.py\", line 1097, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"c:\\Users\\sampa\\anaconda3\\envs\\ml\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 96, in error_handler\n      return fn(*args, **kwargs)\n    File \"c:\\Users\\sampa\\anaconda3\\envs\\ml\\lib\\site-packages\\keras\\engine\\functional.py\", line 510, in call\n      return self._run_internal_graph(inputs, training=training, mask=mask)\n    File \"c:\\Users\\sampa\\anaconda3\\envs\\ml\\lib\\site-packages\\keras\\engine\\functional.py\", line 667, in _run_internal_graph\n      outputs = node.layer(*args, **kwargs)\n    File \"c:\\Users\\sampa\\anaconda3\\envs\\ml\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"c:\\Users\\sampa\\anaconda3\\envs\\ml\\lib\\site-packages\\keras\\engine\\base_layer.py\", line 1097, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"c:\\Users\\sampa\\anaconda3\\envs\\ml\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 96, in error_handler\n      return fn(*args, **kwargs)\n    File \"c:\\Users\\sampa\\anaconda3\\envs\\ml\\lib\\site-packages\\keras\\layers\\core\\dense.py\", line 244, in call\n      outputs = tf.tensordot(inputs, self.kernel, [[rank - 1], [0]])\nNode: 'model/dense/Tensordot/MatMul'\nOOM when allocating tensor with shape[14464,43947] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[{{node model/dense/Tensordot/MatMul}}]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info. This isn't available when running in Eager mode.\n [Op:__inference_train_function_5788]",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[31], line 7\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# Make sure your target data is integer-coded, not one-hot encoded\u001b[39;00m\n\u001b[0;32m      5\u001b[0m decoder_target_data \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39margmax(decoder_target_one_hot, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m----> 7\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43msanskrit_padded\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdecoder_input_data\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdecoder_target_data\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      8\u001b[0m \u001b[43m          \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m64\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m      9\u001b[0m \u001b[43m          \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m100\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     10\u001b[0m \u001b[43m          \u001b[49m\u001b[43mvalidation_split\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.2\u001b[39;49m\u001b[43m)\u001b[49m\n",
            "File \u001b[1;32mc:\\Users\\sampa\\anaconda3\\envs\\ml\\lib\\site-packages\\keras\\utils\\traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
            "File \u001b[1;32mc:\\Users\\sampa\\anaconda3\\envs\\ml\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py:54\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     52\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     53\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 54\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m pywrap_tfe\u001b[38;5;241m.\u001b[39mTFE_Py_Execute(ctx\u001b[38;5;241m.\u001b[39m_handle, device_name, op_name,\n\u001b[0;32m     55\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[0;32m     56\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     57\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
            "\u001b[1;31mResourceExhaustedError\u001b[0m: Graph execution error:\n\nDetected at node 'model/dense/Tensordot/MatMul' defined at (most recent call last):\n    File \"c:\\Users\\sampa\\anaconda3\\envs\\ml\\lib\\runpy.py\", line 197, in _run_module_as_main\n      return _run_code(code, main_globals, None,\n    File \"c:\\Users\\sampa\\anaconda3\\envs\\ml\\lib\\runpy.py\", line 87, in _run_code\n      exec(code, run_globals)\n    File \"c:\\Users\\sampa\\anaconda3\\envs\\ml\\lib\\site-packages\\ipykernel_launcher.py\", line 18, in <module>\n      app.launch_new_instance()\n    File \"c:\\Users\\sampa\\anaconda3\\envs\\ml\\lib\\site-packages\\traitlets\\config\\application.py\", line 1075, in launch_instance\n      app.start()\n    File \"c:\\Users\\sampa\\anaconda3\\envs\\ml\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 739, in start\n      self.io_loop.start()\n    File \"c:\\Users\\sampa\\anaconda3\\envs\\ml\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 205, in start\n      self.asyncio_loop.run_forever()\n    File \"c:\\Users\\sampa\\anaconda3\\envs\\ml\\lib\\asyncio\\base_events.py\", line 601, in run_forever\n      self._run_once()\n    File \"c:\\Users\\sampa\\anaconda3\\envs\\ml\\lib\\asyncio\\base_events.py\", line 1905, in _run_once\n      handle._run()\n    File \"c:\\Users\\sampa\\anaconda3\\envs\\ml\\lib\\asyncio\\events.py\", line 80, in _run\n      self._context.run(self._callback, *self._args)\n    File \"c:\\Users\\sampa\\anaconda3\\envs\\ml\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 545, in dispatch_queue\n      await self.process_one()\n    File \"c:\\Users\\sampa\\anaconda3\\envs\\ml\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 534, in process_one\n      await dispatch(*args)\n    File \"c:\\Users\\sampa\\anaconda3\\envs\\ml\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 437, in dispatch_shell\n      await result\n    File \"c:\\Users\\sampa\\anaconda3\\envs\\ml\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 359, in execute_request\n      await super().execute_request(stream, ident, parent)\n    File \"c:\\Users\\sampa\\anaconda3\\envs\\ml\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 778, in execute_request\n      reply_content = await reply_content\n    File \"c:\\Users\\sampa\\anaconda3\\envs\\ml\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 446, in do_execute\n      res = shell.run_cell(\n    File \"c:\\Users\\sampa\\anaconda3\\envs\\ml\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 549, in run_cell\n      return super().run_cell(*args, **kwargs)\n    File \"c:\\Users\\sampa\\anaconda3\\envs\\ml\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3048, in run_cell\n      result = self._run_cell(\n    File \"c:\\Users\\sampa\\anaconda3\\envs\\ml\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3103, in _run_cell\n      result = runner(coro)\n    File \"c:\\Users\\sampa\\anaconda3\\envs\\ml\\lib\\site-packages\\IPython\\core\\async_helpers.py\", line 129, in _pseudo_sync_runner\n      coro.send(None)\n    File \"c:\\Users\\sampa\\anaconda3\\envs\\ml\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3308, in run_cell_async\n      has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n    File \"c:\\Users\\sampa\\anaconda3\\envs\\ml\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3490, in run_ast_nodes\n      if await self.run_code(code, result, async_=asy):\n    File \"c:\\Users\\sampa\\anaconda3\\envs\\ml\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3550, in run_code\n      exec(code_obj, self.user_global_ns, self.user_ns)\n    File \"C:\\Users\\sampa\\AppData\\Local\\Temp\\ipykernel_24880\\1564568496.py\", line 7, in <module>\n      model.fit([sanskrit_padded, decoder_input_data], decoder_target_data,\n    File \"c:\\Users\\sampa\\anaconda3\\envs\\ml\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"c:\\Users\\sampa\\anaconda3\\envs\\ml\\lib\\site-packages\\keras\\engine\\training.py\", line 1564, in fit\n      tmp_logs = self.train_function(iterator)\n    File \"c:\\Users\\sampa\\anaconda3\\envs\\ml\\lib\\site-packages\\keras\\engine\\training.py\", line 1160, in train_function\n      return step_function(self, iterator)\n    File \"c:\\Users\\sampa\\anaconda3\\envs\\ml\\lib\\site-packages\\keras\\engine\\training.py\", line 1146, in step_function\n      outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"c:\\Users\\sampa\\anaconda3\\envs\\ml\\lib\\site-packages\\keras\\engine\\training.py\", line 1135, in run_step\n      outputs = model.train_step(data)\n    File \"c:\\Users\\sampa\\anaconda3\\envs\\ml\\lib\\site-packages\\keras\\engine\\training.py\", line 993, in train_step\n      y_pred = self(x, training=True)\n    File \"c:\\Users\\sampa\\anaconda3\\envs\\ml\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"c:\\Users\\sampa\\anaconda3\\envs\\ml\\lib\\site-packages\\keras\\engine\\training.py\", line 557, in __call__\n      return super().__call__(*args, **kwargs)\n    File \"c:\\Users\\sampa\\anaconda3\\envs\\ml\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"c:\\Users\\sampa\\anaconda3\\envs\\ml\\lib\\site-packages\\keras\\engine\\base_layer.py\", line 1097, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"c:\\Users\\sampa\\anaconda3\\envs\\ml\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 96, in error_handler\n      return fn(*args, **kwargs)\n    File \"c:\\Users\\sampa\\anaconda3\\envs\\ml\\lib\\site-packages\\keras\\engine\\functional.py\", line 510, in call\n      return self._run_internal_graph(inputs, training=training, mask=mask)\n    File \"c:\\Users\\sampa\\anaconda3\\envs\\ml\\lib\\site-packages\\keras\\engine\\functional.py\", line 667, in _run_internal_graph\n      outputs = node.layer(*args, **kwargs)\n    File \"c:\\Users\\sampa\\anaconda3\\envs\\ml\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"c:\\Users\\sampa\\anaconda3\\envs\\ml\\lib\\site-packages\\keras\\engine\\base_layer.py\", line 1097, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"c:\\Users\\sampa\\anaconda3\\envs\\ml\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 96, in error_handler\n      return fn(*args, **kwargs)\n    File \"c:\\Users\\sampa\\anaconda3\\envs\\ml\\lib\\site-packages\\keras\\layers\\core\\dense.py\", line 244, in call\n      outputs = tf.tensordot(inputs, self.kernel, [[rank - 1], [0]])\nNode: 'model/dense/Tensordot/MatMul'\nOOM when allocating tensor with shape[14464,43947] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[{{node model/dense/Tensordot/MatMul}}]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info. This isn't available when running in Eager mode.\n [Op:__inference_train_function_5788]"
          ]
        }
      ],
      "source": [
        "# Switch to sparse_categorical_crossentropy and provide integer targets\n",
        "model.compile(optimizer='rmsprop', loss='sparse_categorical_crossentropy')\n",
        "\n",
        "# Make sure your target data is integer-coded, not one-hot encoded\n",
        "decoder_target_data = np.argmax(decoder_target_one_hot, axis=-1)\n",
        "\n",
        "model.fit([sanskrit_padded, decoder_input_data], decoder_target_data,\n",
        "          batch_size=64,\n",
        "          epochs=100,\n",
        "          validation_split=0.2)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e7Vt9TNjcQPh"
      },
      "outputs": [],
      "source": [
        "# model.fit([sanskrit_padded, decoder_input_data], decoder_target_one_hot,\n",
        "#           batch_size=32,\n",
        "#           epochs=100,  # Use an appropriate number of epochs\n",
        "#           validation_split=0.2)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5kQjTc4ylvna"
      },
      "outputs": [],
      "source": [
        "encoder_model = Model(encoder_inputs, encoder_states)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6_cbxH3PlwUx"
      },
      "outputs": [],
      "source": [
        "decoder_state_input_h = Input(shape=(latent_dim,))\n",
        "decoder_state_input_c = Input(shape=(latent_dim,))\n",
        "decoder_states_inputs = [decoder_state_input_h, decoder_state_input_c]\n",
        "\n",
        "decoder_outputs, state_h, state_c = decoder_lstm(\n",
        "    decoder_embedding, initial_state=decoder_states_inputs\n",
        ")\n",
        "decoder_states = [state_h, state_c]\n",
        "decoder_outputs = decoder_dense(decoder_outputs)\n",
        "\n",
        "decoder_model = Model(\n",
        "    [decoder_inputs] + decoder_states_inputs,\n",
        "    [decoder_outputs] + decoder_states\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zpM5AOTBly9g"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.19"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
